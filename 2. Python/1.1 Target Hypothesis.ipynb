{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Hypothesis\n",
    "\n",
    "1. Score both Main & Co as two seperate customers\n",
    "\n",
    "bs = fit(bs)\n",
    "\n",
    "ws = fit(ws)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. Make a model of both with Co as a dummy\n",
    "\n",
    "\n",
    "bs = xtrain (bs,ws)\n",
    "\n",
    "\n",
    "2.1 \n",
    "\n",
    "    ws input 0\n",
    "\n",
    "\n",
    "    if 1 Applicant:\n",
    "\n",
    "        bs = xtrain (bs,0)\n",
    "\n",
    "    else:\n",
    "\n",
    "        bs = xtrain (bs,ws)\n",
    "\n",
    "\n",
    "2.2  --> could be adversed selection due to that having a co applicant might say something about the relasionship between the two\n",
    "\n",
    "    ws - applications with co -applicant and for these take the mean \n",
    "\n",
    "\n",
    "    if 1 Applicant:\n",
    "\n",
    "        bs = xtrain (bs,mean(ws))\n",
    "\n",
    "    else:\n",
    "\n",
    "        bs = xtrain (bs,ws)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. Worst \n",
    "\n",
    "if main = main:\n",
    "\n",
    "else:\n",
    "\n",
    "    ws\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "4. Best --makes sence     1. Main -- Always main -->  2. CO --> best score \n",
    "\n",
    "\n",
    "if main = main:\n",
    "\n",
    "else:\n",
    "\n",
    "    bs\n",
    "\n",
    "\n",
    "\n",
    "5. Test two seperate scorecards for main & co\n",
    "\n",
    "5.1 \n",
    "\n",
    "     main = main \n",
    "\n",
    "     Co --> Best \n",
    "\n",
    "5.2\n",
    "\n",
    "     main = main \n",
    "\n",
    "     Co --> CO \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "import sqlalchemy as sa\n",
    "import pyodbc\n",
    "import warnings\n",
    "import urllib\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "################### GET PAYMENT DATA ##########################\n",
    "\n",
    "path = \"../1. Data/Cleaned Transaction Data\"\n",
    "os.chdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('PreeProcessed_Psd2.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReceivedDate</th>\n",
       "      <th>ApplicationID</th>\n",
       "      <th>AccountNumber</th>\n",
       "      <th>SSN</th>\n",
       "      <th>DisbursedDate</th>\n",
       "      <th>Amount</th>\n",
       "      <th>IsMainApplicant</th>\n",
       "      <th>ApplicantNo</th>\n",
       "      <th>HasCoapp</th>\n",
       "      <th>Ever90</th>\n",
       "      <th>...</th>\n",
       "      <th>Unclassified_partOfSalary9Months</th>\n",
       "      <th>Unclassified_sum12Months</th>\n",
       "      <th>Unclassified_sum3Months</th>\n",
       "      <th>Unclassified_sum6Months</th>\n",
       "      <th>Unclassified_sum9Months</th>\n",
       "      <th>sum creditors</th>\n",
       "      <th>sum debtCollectors</th>\n",
       "      <th>count creditors</th>\n",
       "      <th>count debtCollectors</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-08</td>\n",
       "      <td>8205045</td>\n",
       "      <td>0</td>\n",
       "      <td>7711025523</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>250000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>50227.0</td>\n",
       "      <td>224.1</td>\n",
       "      <td>248.5</td>\n",
       "      <td>247.0</td>\n",
       "      <td>258.4</td>\n",
       "      <td>630444</td>\n",
       "      <td>81995</td>\n",
       "      <td>288551</td>\n",
       "      <td>519248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>8228347</td>\n",
       "      <td>0</td>\n",
       "      <td>9804048719</td>\n",
       "      <td>2022-04-22</td>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>763.7</td>\n",
       "      <td>1333.3</td>\n",
       "      <td>1553.4</td>\n",
       "      <td>2678645.0</td>\n",
       "      <td>241491.0</td>\n",
       "      <td>1655157</td>\n",
       "      <td>2249127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>8229075</td>\n",
       "      <td>0</td>\n",
       "      <td>6501225061</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>240000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>85589.0</td>\n",
       "      <td>322.8</td>\n",
       "      <td>415.5</td>\n",
       "      <td>320.5</td>\n",
       "      <td>331.8</td>\n",
       "      <td>882268</td>\n",
       "      <td>279047</td>\n",
       "      <td>442904</td>\n",
       "      <td>685525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>8230481</td>\n",
       "      <td>0</td>\n",
       "      <td>9606236371</td>\n",
       "      <td>2022-04-13</td>\n",
       "      <td>295000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>268.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>439.5</td>\n",
       "      <td>883993.0</td>\n",
       "      <td>100348.0</td>\n",
       "      <td>452428</td>\n",
       "      <td>627919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-15</td>\n",
       "      <td>8233936</td>\n",
       "      <td>0</td>\n",
       "      <td>8602147608</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>270000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>379.3</td>\n",
       "      <td>1362741.0</td>\n",
       "      <td>251386.0</td>\n",
       "      <td>547363.0</td>\n",
       "      <td>971946.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>8660675</td>\n",
       "      <td>0</td>\n",
       "      <td>8902289209</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>271000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>195.3</td>\n",
       "      <td>381102.0</td>\n",
       "      <td>84024.0</td>\n",
       "      <td>274075.0</td>\n",
       "      <td>312523.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>8660675</td>\n",
       "      <td>0</td>\n",
       "      <td>8903213695</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>271000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.2</td>\n",
       "      <td>348937.0</td>\n",
       "      <td>91087.0</td>\n",
       "      <td>215240.0</td>\n",
       "      <td>265065.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>8660600</td>\n",
       "      <td>0</td>\n",
       "      <td>8007075586</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>350000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>40754.0</td>\n",
       "      <td>165.3</td>\n",
       "      <td>135.9</td>\n",
       "      <td>130.5</td>\n",
       "      <td>145.1</td>\n",
       "      <td>509094</td>\n",
       "      <td>147353</td>\n",
       "      <td>245526</td>\n",
       "      <td>367844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>8660600</td>\n",
       "      <td>0</td>\n",
       "      <td>8203014934</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>350000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38839.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>76.7</td>\n",
       "      <td>72.3</td>\n",
       "      <td>92.7</td>\n",
       "      <td>487593</td>\n",
       "      <td>113811</td>\n",
       "      <td>198074</td>\n",
       "      <td>353883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>8661965</td>\n",
       "      <td>0</td>\n",
       "      <td>9106092506</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>210000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18829.0</td>\n",
       "      <td>133.1</td>\n",
       "      <td>161.4</td>\n",
       "      <td>128.7</td>\n",
       "      <td>121.5</td>\n",
       "      <td>241308</td>\n",
       "      <td>44420</td>\n",
       "      <td>106884</td>\n",
       "      <td>161468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3493 rows Ã— 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ReceivedDate  ApplicationID  AccountNumber         SSN DisbursedDate  \\\n",
       "0      2022-03-08        8205045              0  7711025523    2022-03-10   \n",
       "1      2022-04-07        8228347              0  9804048719    2022-04-22   \n",
       "2      2022-04-08        8229075              0  6501225061    2022-04-12   \n",
       "3      2022-04-11        8230481              0  9606236371    2022-04-13   \n",
       "4      2022-04-15        8233936              0  8602147608    2022-06-08   \n",
       "...           ...            ...            ...         ...           ...   \n",
       "3488   2023-04-28        8660675              0  8902289209    2023-05-31   \n",
       "3489   2023-04-28        8660675              0  8903213695    2023-05-31   \n",
       "3490   2023-04-28        8660600              0  8007075586    2023-05-08   \n",
       "3491   2023-04-28        8660600              0  8203014934    2023-05-08   \n",
       "3492   2023-04-30        8661965              0  9106092506    2023-05-09   \n",
       "\n",
       "      Amount  IsMainApplicant  ApplicantNo  HasCoapp  Ever90  ...  \\\n",
       "0     250000                1            1         0       1  ...   \n",
       "1     400000                1            1         1       1  ...   \n",
       "2     240000                1            1         0       1  ...   \n",
       "3     295000                1            1         0       1  ...   \n",
       "4     270000                1            1         0       1  ...   \n",
       "...      ...              ...          ...       ...     ...  ...   \n",
       "3488  271000                1            1         1       0  ...   \n",
       "3489  271000                0            2         1       0  ...   \n",
       "3490  350000                1            1         1       0  ...   \n",
       "3491  350000                0            2         1       0  ...   \n",
       "3492  210000                1            1         1       0  ...   \n",
       "\n",
       "      Unclassified_partOfSalary9Months  Unclassified_sum12Months  \\\n",
       "0                              50227.0                     224.1   \n",
       "1                                763.7                    1333.3   \n",
       "2                              85589.0                     322.8   \n",
       "3                                268.0                     476.0   \n",
       "4                                379.3                 1362741.0   \n",
       "...                                ...                       ...   \n",
       "3488                             195.3                  381102.0   \n",
       "3489                             121.2                  348937.0   \n",
       "3490                           40754.0                     165.3   \n",
       "3491                           38839.0                      96.0   \n",
       "3492                           18829.0                     133.1   \n",
       "\n",
       "      Unclassified_sum3Months  Unclassified_sum6Months  \\\n",
       "0                       248.5                    247.0   \n",
       "1                      1553.4                2678645.0   \n",
       "2                       415.5                    320.5   \n",
       "3                       439.5                 883993.0   \n",
       "4                    251386.0                 547363.0   \n",
       "...                       ...                      ...   \n",
       "3488                  84024.0                 274075.0   \n",
       "3489                  91087.0                 215240.0   \n",
       "3490                    135.9                    130.5   \n",
       "3491                     76.7                     72.3   \n",
       "3492                    161.4                    128.7   \n",
       "\n",
       "      Unclassified_sum9Months  sum creditors  sum debtCollectors  \\\n",
       "0                       258.4         630444               81995   \n",
       "1                    241491.0        1655157             2249127   \n",
       "2                       331.8         882268              279047   \n",
       "3                    100348.0         452428              627919   \n",
       "4                    971946.0              0                   0   \n",
       "...                       ...            ...                 ...   \n",
       "3488                 312523.0              0                   0   \n",
       "3489                 265065.0              0                   0   \n",
       "3490                    145.1         509094              147353   \n",
       "3491                     92.7         487593              113811   \n",
       "3492                    121.5         241308               44420   \n",
       "\n",
       "      count creditors  count debtCollectors  _merge  \n",
       "0              288551                519248       0  \n",
       "1                   0                     0       0  \n",
       "2              442904                685525       0  \n",
       "3                   0                     0       0  \n",
       "4                   0                     0       0  \n",
       "...               ...                   ...     ...  \n",
       "3488                0                     0       0  \n",
       "3489                0                     0       0  \n",
       "3490           245526                367844       0  \n",
       "3491           198074                353883       0  \n",
       "3492           106884                161468       0  \n",
       "\n",
       "[3493 rows x 280 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# git add .\n",
    "\n",
    "# git commit -m \"Finalised API Loop\"\n",
    "\n",
    "#  git status\n",
    "\n",
    "#  git push origin Andreas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def upsample(self, target_column):\n",
    "        \"\"\"\n",
    "        Up-sample the minority class of a DataFrame based on the target column.\n",
    "\n",
    "        Parameters:\n",
    "        - target_column: string, the name of the target column\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame with balanced classes\n",
    "        \"\"\"\n",
    "        df_minority = self.df[self.df[target_column] == self.df[target_column].value_counts().idxmin()]\n",
    "        df_majority = self.df[self.df[target_column] != self.df[target_column].value_counts().idxmin()]\n",
    "\n",
    "        df_minority_upsampled = df_minority.sample(n=len(df_majority), replace=True, random_state=42)\n",
    "        df_upsampled = pd.concat([df_majority, df_minority_upsampled], axis=0)\n",
    "        \n",
    "        return df_upsampled\n",
    "\n",
    "    def from_quartile_idx(self, quartile):\n",
    "        \"\"\"\n",
    "        Get the index of the quartile in df when creating train/test splits.\n",
    "\n",
    "        Parameters:\n",
    "        - quartile: float, the quartile to split on\n",
    "\n",
    "        Returns:\n",
    "        - position: int, the index position in the DataFrame\n",
    "        \"\"\"\n",
    "        df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        counter = 0\n",
    "        eighty = np.round(df.Ever90.value_counts()[1] * quartile)\n",
    "        position = 0\n",
    "\n",
    "        for idx, i in enumerate(df.Ever90):\n",
    "            if i == 1:\n",
    "                counter += 1 \n",
    "            if counter == eighty:\n",
    "                position = idx\n",
    "                print(position)\n",
    "                break \n",
    "\n",
    "        print('Position in df cut:', position / len(df))\n",
    "        return position\n",
    "\n",
    "    def get_split_data_with_upsample_and_scaling(self, quartile1):\n",
    "        \"\"\"\n",
    "        Get upsampled data where the split is based on a specified quartile to harmonize distribution,\n",
    "        and then scale the data.\n",
    "\n",
    "        Parameters:\n",
    "        - quartile1: float, the quartile to split on\n",
    "\n",
    "        Returns:\n",
    "        - Tuple containing (Xtrain, Ytrain), (Xtest, Ytest), and train_upsampled\n",
    "        \"\"\"\n",
    "        print('Binary Split: ' + str(self.df.Ever90.value_counts()))\n",
    "\n",
    "        position1 = self.from_quartile_idx(quartile1)\n",
    "        train, test = self.df.iloc[:position1], self.df.iloc[position1:]\n",
    "\n",
    "        # Upsample only the training data\n",
    "        train_upsampled = self.upsample('Ever90')\n",
    "        print(train_upsampled.Ever90.value_counts())\n",
    "\n",
    "        # Create Xtrain, Ytrain, Xtest, Ytest\n",
    "        Xtrain, Ytrain = train_upsampled.drop(columns='Ever90'), train_upsampled['Ever90']\n",
    "        Xtest, Ytest = test.drop(columns='Ever90'), test['Ever90']\n",
    "\n",
    "        # Scale the data\n",
    "        scaler = StandardScaler()\n",
    "        Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
    "        Xtest_scaled = scaler.transform(Xtest)\n",
    "\n",
    "        return (Xtrain_scaled, Ytrain.values), (Xtest_scaled, Ytest.values), train_upsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ReceivedDate','ApplicationID','SSN','DisbursedDate','Amount','IsMainApplicant','ApplicantNo','NR'])\n",
    "\n",
    "forforsta = df.drop(columns=['HasCoapp'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Split: Ever90\n",
      "0    3170\n",
      "1     323\n",
      "Name: count, dtype: int64\n",
      "2434\n",
      "Position in df cut: 0.696822215860292\n",
      "Ever90\n",
      "0    3170\n",
      "1    3170\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preprocessor = DataPreprocessor(forforsta)\n",
    "(Xtrain, Ytrain), (Xtest, Ytest), train_upsampled,  = preprocessor.get_split_data_with_upsample_and_scaling(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.66024429, -0.03834957, ..., -0.14059477,\n",
       "        -0.16299462,  0.        ],\n",
       "       [ 0.        , -0.06464579, -0.03834957, ..., -0.6117184 ,\n",
       "        -0.65450127,  0.        ],\n",
       "       [ 0.        , -0.3724951 , -0.03834957, ..., -0.6117184 ,\n",
       "        -0.65450127,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.66530619, -0.03834957, ..., -0.6117184 ,\n",
       "        -0.65450127,  0.        ],\n",
       "       [ 0.        , -0.61634138, -0.03834957, ...,  0.48079613,\n",
       "         0.36468438,  0.        ],\n",
       "       [ 0.        , -0.58195958, -0.03834957, ..., -0.6117184 ,\n",
       "        -0.65450127,  0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial, model_name, X_train, y_train):\n",
    "    if model_name == 'svm':\n",
    "        C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
    "        kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "        degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "        gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "        model = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma)\n",
    "        \n",
    "    elif model_name == 'xgboost':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
    "        model = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate)\n",
    "        \n",
    "    elif model_name == 'random_forest':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "        max_depth = trial.suggest_int('max_depth', 5, 20)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "        \n",
    "    elif model_name == 'logistic_regression':\n",
    "        C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
    "        penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet', 'none'])\n",
    "        solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'saga', 'sag'])\n",
    "        model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=10000)\n",
    "\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "def optimize_model(model_name, X_train, y_train, n_trials=2):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, model_name, X_train, y_train), n_trials=n_trials)\n",
    "    return study.best_params\n",
    "\n",
    "def train_best_model(model_name, best_params, X_train, y_train):\n",
    "    if model_name == 'svm':\n",
    "        model = SVC(**best_params)\n",
    "    elif model_name == 'xgboost':\n",
    "        model = XGBClassifier(**best_params)\n",
    "    elif model_name == 'random_forest':\n",
    "        model = RandomForestClassifier(**best_params)\n",
    "    elif model_name == 'logistic_regression':\n",
    "        model = LogisticRegression(**best_params, max_iter=10000)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "# Assuming train and test data are numpy arrays\n",
    "# Replace these with your actual data\n",
    "# X_train, X_test, y_train, y_test = np.array(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-17 15:59:18,289] A new study created in memory with name: no-name-60a64647-b69b-45e1-9ea9-112973b41159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing svm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-17 15:59:29,482] Trial 0 finished with value: 0.5225480174612477 and parameters: {'C': 0.001187780281131538, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.5225480174612477.\n",
      "[I 2024-05-17 15:59:37,556] Trial 1 finished with value: 0.5709777722656056 and parameters: {'C': 0.030061526722114755, 'kernel': 'poly', 'degree': 5, 'gamma': 'auto'}. Best is trial 1 with value: 0.5709777722656056.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for svm: {'C': 0.030061526722114755, 'kernel': 'poly', 'degree': 5, 'gamma': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-17 15:59:41,743] A new study created in memory with name: no-name-db39a4ea-d113-4516-b7f5-8b1d230548a7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing xgboost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-17 15:59:45,324] Trial 0 finished with value: 0.9856484530671134 and parameters: {'n_estimators': 168, 'max_depth': 11, 'learning_rate': 0.21979608933530537}. Best is trial 0 with value: 0.9856484530671134.\n",
      "[I 2024-05-17 15:59:49,338] Trial 1 finished with value: 0.9856486023136496 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.1690636482579104}. Best is trial 1 with value: 0.9856486023136496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for xgboost: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.1690636482579104}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-17 15:59:50,888] A new study created in memory with name: no-name-1fcf1108-c6b1-4e28-97c8-7f7e215644a6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing logistic_regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-17 15:59:55,851] Trial 0 finished with value: 0.686593765703534 and parameters: {'C': 29.567169611610247, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.686593765703534.\n",
      "[I 2024-05-17 16:01:40,163] Trial 1 finished with value: 0.6854925501352697 and parameters: {'C': 1.1169990427014118, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 0 with value: 0.686593765703534.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for logistic_regression: {'C': 29.567169611610247, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-17 16:01:40,957] A new study created in memory with name: no-name-cb0fe2d3-f534-427b-8b9d-d8b5b524dc74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing random_forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-17 16:01:46,664] Trial 0 finished with value: 0.988960606824477 and parameters: {'n_estimators': 148, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.988960606824477.\n",
      "[I 2024-05-17 16:01:53,458] Trial 1 finished with value: 0.985490177115342 and parameters: {'n_estimators': 184, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.988960606824477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for random_forest: {'n_estimators': 148, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 1}\n",
      "Accuracy of svm: 1.0\n",
      "Accuracy of xgboost: 1.0\n",
      "Accuracy of logistic_regression: 0.7299338999055713\n",
      "Accuracy of random_forest: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svm': SVC(C=0.030061526722114755, degree=5, gamma='auto', kernel='poly'),\n",
       " 'xgboost': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "               gamma=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.1690636482579104,\n",
       "               max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "               num_parallel_tree=None, random_state=None, ...),\n",
       " 'logistic_regression': LogisticRegression(C=29.567169611610247, max_iter=10000),\n",
       " 'random_forest': RandomForestClassifier(max_depth=15, min_samples_split=6, n_estimators=148)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "models = ['svm', 'xgboost', 'logistic_regression', 'random_forest']\n",
    "best_params = {}\n",
    "best_models = {}\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Optimizing {model}...\")\n",
    "    best_params[model] = optimize_model(model, Xtrain, Ytrain)\n",
    "    print(f\"Best parameters for {model}: {best_params[model]}\")\n",
    "    best_models[model] = train_best_model(model, best_params[model], Xtrain, Ytrain)\n",
    "\n",
    "# Training and evaluating the best model\n",
    "for model_name, model in best_models.items():\n",
    "    Ypred = model.predict(Xtest)\n",
    "    accuracy = accuracy_score(Ytest, Ypred)\n",
    "    print(f\"Accuracy of {model_name}: {accuracy}\")\n",
    "\n",
    "# Return the best models\n",
    "best_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svm': SVC(C=0.030061526722114755, degree=5, gamma='auto', kernel='poly'),\n",
       " 'xgboost': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "               gamma=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.1690636482579104,\n",
       "               max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "               num_parallel_tree=None, random_state=None, ...),\n",
       " 'logistic_regression': LogisticRegression(C=29.567169611610247, max_iter=10000),\n",
       " 'random_forest': RandomForestClassifier(max_depth=15, min_samples_split=6, n_estimators=148)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory 1 \n",
    "\n",
    "1. Score both Main & Co as two seperate customers\n",
    "\n",
    "bs = fit(bs)\n",
    "\n",
    "ws = fit(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing svm...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimize_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     best_params[model] \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_model\u001b[49m(model, X_train, y_train)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     best_models[model] \u001b[38;5;241m=\u001b[39m train_best_model(model, best_params[model], X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimize_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "# Replace with your actual data\n",
    "# X_train, X_test, y_train, y_test = np.array(...)\n",
    "\n",
    "models = ['svm', 'xgboost', 'lightgbm', 'random_forest']\n",
    "best_params = {}\n",
    "best_models = {}\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Optimizing {model}...\")\n",
    "    best_params[model] = optimize_model(model, X_train, y_train)\n",
    "    print(f\"Best parameters for {model}: {best_params[model]}\")\n",
    "    best_models[model] = train_best_model(model, best_params[model], X_train, y_train)\n",
    "\n",
    "# Training and evaluating the best model\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy of {model_name}: {accuracy}\")\n",
    "\n",
    "# Return the best models\n",
    "best_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
